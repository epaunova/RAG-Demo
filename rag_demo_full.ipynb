{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "272b46e7",
   "metadata": {},
   "source": [
    "# Retrieval‑Augmented Generation (RAG) Demo\n",
    "**Eva Paunova – June 2025**\n",
    "\n",
    "This notebook demonstrates a minimal but complete RAG pipeline:\n",
    "1. Load unstructured docs\n",
    "2. Chunk & embed via Hugging Face\n",
    "3. Store vectors in pgvector (PostgreSQL)\n",
    "4. Retrieve with LangChain and query LLM\n",
    "5. Record latency & cost metrics\n",
    "\n",
    "Feel free to swap components (e.g. Pinecone instead of pgvector, Mistral instead of OpenAI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82965e57",
   "metadata": {},
   "source": [
    "## 1 · Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7adcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain sentence-transformers pgvector psycopg2-binary openai\n",
    "import os, time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19c9881",
   "metadata": {},
   "source": [
    "### 1.1 Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'sk-REPLACE_ME'\n",
    "CONN_STR = 'postgresql://rag_user:rag_pass@localhost:5432/ragdemo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53720c31",
   "metadata": {},
   "source": [
    "## 2 · Load sample documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82410505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "urls = [\n",
    "    'https://www.nvidia.com/en-us/blog/what-is-generative-ai/',\n",
    "    'https://huggingface.co/blog/rag'  # any public article\n",
    "]\n",
    "loader = UnstructuredURLLoader(urls)\n",
    "docs = loader.load()[:10]\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bd2230",
   "metadata": {},
   "source": [
    "### 2.1 Chunk & embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee525694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=60)\n",
    "chunks = splitter.split_documents(docs)\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embedder = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f0d6bd",
   "metadata": {},
   "source": [
    "## 3 · Vector store (pgvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dceb41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import PGVector\n",
    "vectordb = PGVector.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedder,\n",
    "    connection_string=CONN_STR,\n",
    "    collection_name='demo_chunks'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7c233c",
   "metadata": {},
   "source": [
    "## 4 · RAG Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e244eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(model_name='gpt-3.5-turbo', temperature=0.2),\n",
    "    chain_type='stuff',\n",
    "    retriever=vectordb.as_retriever(k=3)\n",
    ")\n",
    "query = 'Explain retrieval‑augmented generation in two sentences.'\n",
    "start = time.time()\n",
    "response = qa_chain.run(query)\n",
    "latency = time.time() - start\n",
    "print(response)\n",
    "print(f'Latency: {latency:.2f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0637f1",
   "metadata": {},
   "source": [
    "## 5 · Mini evaluation – cost & latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e676d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tokens = 40  # stub values\n",
    "completion_tokens = 80\n",
    "cost = (prompt_tokens + completion_tokens) / 1000 * 0.0015  # $/1k for gpt-3.5\n",
    "print(f'Approx cost: ${cost:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5600cd",
   "metadata": {},
   "source": [
    "## 6 · Next steps / TODO\n",
    "* Replace URLs with your own knowledge base\n",
    "* Swap pgvector for Pinecone or Chroma\n",
    "* Add BERTScore evaluation\n",
    "* Deploy via FastAPI for real-time use\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
